---
description: 消费者
---

# Consumer

## 消费者和消费组

与生产者对应的就是消费者，消费者（Consumer）负责订阅 Kafka 中的主题（Topic），并且从订阅的主题上拉取消息。

对于 Kafka 来说，Consumer 与 Topic 之前还有一层消息组（Consumer Group），每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。消费者组是 Kafka 实现 **单播** 和 **广播** 两种消息模型的基础和手段。对于同一个Topic 来说，每个消费者组都可以拿到这个 Topic 中的全部数据。消费者组内的所有消费者协调在一起来订阅并消费 Kafka Topic 中的所有分区。这里，每个分区只能由同一个消费者组内的一个消费者来消费。

对于消息中间件而言，一般有两种消息投递模式：**点对点（P2P，Point-to-Point）模式** 和 **发布/订阅（Pub/Sub）模式**：

* 点对点模式是基于队列的，消息生产者发送消息到队列，消息消费者从队列中接收消息。
* 发布/订阅模式则应用在消息的一对多广播时；

Topic 使得消息的订阅者和发布者互相保持独立，Kafka 同时支持两种消息投递模式，而这正是得益于消费者与消费组模型的契合：

* 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于点对点模式的应用。
* 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于发布/订阅模式的应用。

消费组是一个逻辑上的概念，它将旗下的消费者归为一类，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数 `group.id` 来配置，默认值为空字符串。消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个线程，也可以是一个进程。同一个消费组内的消费者既可以部署在同一台机器上，也可以部署在不同的机器上。

### Partition 和消费者对应关系

kafka 为了保证同一类型的消息顺序性（FIFO），一个 Partition 只能被同一组的一个 Consumer 消费，不同组的 Consumer 可以消费同一个 Partition。但是一个 Consumer 可以消费多个 Partition。其消费关系如下：

* `Consumer > Partition`：当 Consumer 数量大于 Partition 数量时，同一个 Partition 内的消息只能被同一个组中的一个 Consumer 消费。多余的消费者空闲。
* `Consumer < Partition`：存在一个 Consumer 消费多个 Partition 的情况；
* `Consumer = Partition`：Consumer 和 Partition 之前是一一对应的关系，一个 Consumer 负责一个 Partition。

即同一个partition内的消息只能被同一个组中的一个consumer消费。当消费者数量多于partition的数量时，多余的消费者空闲。

### 消费步骤

一个正常的消费逻辑需要具备以下几个步骤：

1. 配置消费者客户端参数及创建相应的消费者实例。
2. 订阅主题。
3. 拉取消息并消费。
4. 提交消费位移。
5. 关闭消费者实例。

## 如何选择合适的分区数

那么何为分区呢？主题作为消息的归类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。

分区是 Kafka 中最小的并行操作单元，对生产者而言，每一个分区的数据写入是完全可以并行化的；对消费者而言，Kafka 只允许单个分区中的消息被一个消费者线程消费，一个消费组的消费并行度完全依赖于所消费的分区数。

从 Kafka 的底层实现来说，主题和分区都是逻辑上的概念，分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。

### 影响因素

Kafka 性能测试主要依赖其自身提供的工具，即：用于生产者性能测试的 `kafka-producer-perf-test.sh` 和用于消费者性能测试的 `kafka-consumer-perf-test.sh`。

性能的比较主要看 **吞吐量**，消息的吞吐量不仅受硬件资源的影响，还会受消息大小、、消息压缩方式、消息发送方式（同步/异步）、消息确认类型（acks）、副本因子等参数的影响。消息消费的吞吐量还会受到应用逻辑处理速度的影响。这里我们保证所有的因子一致即可，只测试主题的分区数不同。

### 文件描述符

经过测试我们可以看到分区数为 1 时吞吐量最低，随着分区数的增长，相应的吞吐量也跟着上涨。一旦分区数超过了某个阈值之后，整体的吞吐量是不升反降的。也就是说，并不是分区数越多吞吐量也越大。

并且分区数也并不能一直增加，如果超过默认的配置值，还会引起 Kafka 进程的崩溃。其中一个原因是 `文件描述符不足`。这个情况下，我们可以根据系统资源来调大这个参数，比如使用 `ulimit-n 65535` 命令将上限提高到 65535，这样足以应对大多数的应用情况。

### 消息写入

另外，当生产者向 Kafka 中写入基于 key 的消息时，Kafka 通过消息的 key 来计算出消息将要写入哪个具体的分区，这样具有相同 key 的数据可以写入同一个分区。

比如对于同一个 key 的所有消息，消费者需要按消息的顺序进行有序的消费，如果分区的数量发生变化，那么有序性就得不到保证。在创建主题时，最好能确定好分区数，这样也可以省去后期增加分区所带来的多余操作。尤其对于与 key 高关联的应用，在创建主题时可以适当地多创建一些分区，以满足未来的需求。

### 系统可用性

分区数的多少还会影响系统的可用性。Kafka 通过多副本机制来实现集群的高可用和高可靠，每个分区都会有一至多个副本，每个副本分别存在于不同的 broker 节点上，并且只有 leader 副本对外提供服务。在K afka 集群的内部，所有的副本都采用自动化的方式进行管理，并确保所有副本中的数据都能保持一定程度上的同步。当 broker 发生故障时，leader 副本所属宿主的 broker 节点上的所有分区将暂时处于不可用的状态，此时 Kafka 会自动在其他的 follower 副本中选举出新的 leader 用于接收外部客户端的请求，整个过程由 Kafka 控制器负责完成。分区在进行 leader 角色切换的过程中会变得不可用，不过对于单个分区来说这个过程非常短暂，对用户而言可以忽略不计。如果集群中的某个 broker 节点宕机，那么就会有大量的分区需要同时进行 leader 角色切换，这个切换的过程会耗费一笔可观的时间，并且在这个时间窗口内这些分区也会变得不可用。

分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间。
