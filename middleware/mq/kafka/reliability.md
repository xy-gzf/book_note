---
description: 可靠性探究
---

# Reliability

## 副本

#### leader 副本和 follow 副本

**副本是相对于分区而言的，即副本是特定分区的副本。**

一个分区中包含一个或多个副本，其中一个为 leader 副本，其余为 follower 副本，各个副本位于不同的 broker 节点中。只有 leader 副本对外提供服务，follower 副本只负责数据同步。

#### AR 和 ISR

分区中的所有副本统称为 AR（Assigned Repllicas），而 ISR（In-Sync Replicas） 是指与leader 副本保持同步状态的副本集合，当然 leader 副本本身也是这个集合中的一员。ISR 集合是 AR 集合中的一个子集。

#### LEO 和 HW

LEO（Log End Offset的）表示了当前日志文件中下一条待写入消息的 offset，LEO 的大小相当于当前日志分区中最后一条消息的 offset 值加 1。分区 ISR 集合中的每个副本都会维护自身的 LEO，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费这而言只能消费 HW 之前的消息。

### 失效副本和失效分区

正常情况下，分区的所有副本都处于 ISR 集合中，但是难免会有异常情况发生，从而某些副本被剥离出 ISR 集合中。在 ISR 集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即 under-replicated 分区。

失效副本不仅是指处于功能失效状态的副本，处于同步失效状态的副本也可以看作失效副本。Kafka 通过唯一的 broker 端参数 `replica.lag.time.max.ms` 来判断一个副本是否为同步实效副本，当 ISR 集合中的一个 follower 副本滞后 leader 副本的时间超过此参数指定的值时则判定为同步失败，需要将此 follower 副本剔除出 ISR 集合。replica.lag.time.max.ms 参数的默认值为 10000。

其实现原理为：当 follower 副本将 leader 副本 LEO（LogEndOffset）之前的日志全部同步时，则认为该 follower 副本已经追赶上 leader 副本，此时更新该副本的 lastCaughtUpTimeMs 标识。

Kafka 的副本管理器会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的 lastCaughtUpTimeMs 差值是否大于参数 replica.lag.time.max.ms 指定的值。

**注意：follower 副本 拉取 leader 副本的数据不一定就会更新 lastCaughtUpTimeMs。**  试想一下，当 leader 副本中消息的流入速度大于 follower 副本中拉取的速度时，就算 follower 副本一直不断地拉取 leader 副本的消息也不能与 leader 副本同步。如果还将此 follower 副本置于 ISR 集合中，那么当 leader 副本下线而选取此 follower 副本为新的 leader 副本时就会造成消息的严重丢失。

一般有两种情况会导致副本失效：

* **follower 副本进程卡住，在一段时间内根本没有向 leader 副本发起同步请求，比如频繁的 Full GC。**
* **follower 副本进程同步过慢，在一段时间内都无法追赶上 leader 副本，比如 I/O 开销过大。**

### ISR 扩缩容

#### 缩容

Kafka 在启动的时候会开启两个与 ISR 相关的定时任务，名称分别为“isr-expiration”和“isr-change-propagation”。isr-expiration 任务会周期性地检测每个分区是否需要缩减其 ISR 集合。当检测到 ISR 集合中有失效副本时，就会收缩 ISR 集合。

如果某个分区的 ISR 集合发生变更，则会将变更后的数据记录到 ZooKeeper 对应的 /brokers/topics/＜topic＞/partition/＜parititon＞/state 节点中。

除此之外，当 ISR 集合发生变更时还会将变更后的记录缓存到 `isrChangeSet` 中，isr-change-propagation 任务会周期性（固定值为 2500ms）地检查 isrChangeSet，如果发现 isrChangeSet 中有 ISR 集合的变更记录，那么它会在 ZooKeeper的 /isr\_change\_notification 路径下创建一个以 isr\_change\_开头的持久顺序节点并将 isrChangeSet 中的信息保存到这个节点中。

Kafka控 制器为 /isr\_change\_notification 添加了一个 Watcher，当这个节点中有子节点发生变化时会触发 Watcher 的动作，**以此通知控制器更新相关元数据信息并向它管理的 broker 节点发送更新元数据的请求，最后删除 /isr\_change\_notification 路径下已经处理过的节点。**

注意：频繁地触发 Watcher 会影响 Kafka 控制器、ZooKeeper 甚至其他 broker 节点的性能。为了避免这种情况，Kafka 添加了限定条件，当检测到分区的 ISR 集合发生变化时，还需要检查以下两个条件：

1. **上一次 ISR 集合发生变化距离现在已经超过 5s。**
2. **上一次写入 ZooKeeper 的时间距离现在已经超过 60s。**

满足以上两个条件之一才可以将 ISR 集合的变化写入目标节点。

#### 扩容

随着 follower 副本不断与 leader 副本进行消息同步，follower 副本的 LEO 也会逐渐后移，并最终追赶上 leader 副本，此时该 follower 副本就有资格进入 ISR 集合。

`追赶上 leader 副本的判定准则是此副本的 LEO 是否不小于 leader 副本的 HW`

## 日志同步机制

在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。虽然有许多方式可以实现这些功能，但最简单高效的方式还是从集群中选出一个 leader 来负责处理数据写入的顺序性。只要 leader 还处于存活状态，那么 follower 只需按照 leader 中的写入顺序来进行同步即可。

日志同步机制的一个基本原则就是：`如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的 leader 中能够包含这条消息`。

这里就有一个需要权衡（tradeoff）的地方，如果 leader 在消息被提交前需要等待更多的 follower 确认，那么在它宕机之后就可以有更多的 follower 替代它，不过这也会造成性能的下降。

### 少数服从多数

对于这种 tradeoff，一种常见的做法是“少数服从多数”，它可以用来负责提交决策和选举决策。

在这种方式下，如果我们有 2f+1 个副本，那么在提交之前必须保证有 f+1 个副本同步完消息。同时为了保证能正确选举出新的 leader，至少要保证有 f+1 个副本节点完成日志同步并从同步完成的副本中选举出新的 leader 节点。并且在不超过 f 个副本节点失败的情况下，新的 leader 需要保证不会丢失已经提交过的全部消息。这样在任意组合的 f+1 个副本中，理论上可以确保至少有一个副本能够包含已提交的全部消息，这个副本的日志拥有最全的消息，因此会有资格被选举为新的 leader 来对外提供服务。

#### 优劣势

“少数服从多数”的方式有一个很大的优势，`系统的延迟取决于最快的几个节点`，比如副本数为 3，那么延迟就取决于最快的那个 follower 而不是最慢的那个（除了 leader，只需要另一个 follower 确认即可）。

不过它也有一些劣势，`为了保证 leader 选举的正常进行，它所能容忍的失败 follower 数比较少`，如果要容忍 1 个 follower 失败，那么至少要有 3 个副本，如果要容忍 2 个 follower 失败，必须要有 5 个副本。也就是说，`在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降`。这也就是“少数服从多数”的这种 Quorum 模型常被用作共享集群配置（比如 ZooKeeper），而很少用于主流的数据存储中的原因。

### ISR 集合选举

Kafka 采用的是另外一种方式。

在 Kafka 中动态维护着一个 ISR 集合，处于 ISR 集合内的节点保持与 leader 相同的高水位（HW），只有位列其中的副本才有资格被选为新的 leader。写入消息时只有等到所有 ISR 集合中的副本都确认收到之后才能被认为已经提交。位于 ISR 中的任何副本节点都有资格成为leader。

#### 优劣势

这种方式选举过程简单、开销低，这也是 Kafka 选用此模型的重要因素。Kafka 中包含大量的分区，leader 副本的均衡保障了整体负载的均衡，所以这一因素也极大地影响 Kafka 的性能指标。

在采用 ISR 模型和（f+1）个副本数的配置下，一个 Kafka 分区能够容忍最大 f 个节点失败，相比于“少数服从多数”的方式所需的节点数大幅减少。

在需要相同确认信息数的情况下，采用 ISR 的方式所需要的副本总数变少，复制带来的集群开销也就更低，“少数服从多数”的优势在于它可以绕开最慢副本的确认信息，降低提交的延迟，而对Kafka 而言，这种能力可以交由客户端自己去选择。

## 可靠性设置

### 副本数量

就 Kafka 而言，越多的副本数越能够保证数据的可靠性，副本数可以在创建主题时配置，也可以在后期修改，不过副本数越多也会引起磁盘、网络带宽的浪费，同时会引起性能的下降。

**一般而言，设置副本数为 3 即可满足绝大多数场景对可靠性的要求，而对可靠性要求更高的场景下，可以适当增大这个数值。**

### ack

ACK 参数的三个可选值。

即对于 ack=-1 的配置，生产者将消息发送到 leader 副本，leader 副本在成功写入本地日志之后还要等待 ISR 中的 follower 副本全部同步完成才能够告知生产者已经成功提交，即使此时leader副本宕机，消息也不会丢失。同样如果在消息成功写入 leader 副本之后，并且在被 ISR 中的所有副本同步之前 leader 副本宕机了，那么生产者会收到异常以此告知此次发送失败。

### 消息发送模式

消息发送的 3 种模式，即发后即忘、同步和异步。对于发后即忘的模式，不管消息有没有被成功写入，生产者都不会收到通知，那么即使消息写入失败也无从得知，因此发后即忘的模式不适合高可靠性要求的场景。如果要提升可靠性，那么生产者可以采用同步或异步的模式，在出现异常情况时可以及时获得通知，以便可以做相应的补救措施，比如选择重试发送。

### 重试

有些发送异常属于可重试异常，比如 NetworkException，这个可能是由瞬时的网络故障而导致的，一般通过重试就可以解决。重试参数配置为 retries，默认情况下，retries 参数设置为 0，即不进行重试，对于高可靠性要求的场景，需要将这个值设置为大于 0 的值。

与 retries 参数相关的还有一个 retry.backoff.ms 参数，它用来设定 `两次重试之间的时间间隔`，以此避免无效的频繁重试。在配置 retries 和 retry.backoff.ms 之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。如果不知道 retries 参数应该配置为多少，则可以参考 KafkaAdminClient，在 KafkaAdminClient 中 retries 参数的默认值为 5。

### 刷盘策略

在 broker 端还有两个参数 log.flush.interval.messages 和 log.flush.interval.ms，用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。同步刷盘是增强一个组件可靠性的有效方式。

但是不建议设置成同步刷盘，原因是绝大多数情景下，一个组件（尤其是大数据量的组件）的可靠性不应该由同步刷盘这种极其损耗性能的操作来保障，而应该采用多副本的机制来保障。

### 手动提交消费位移

Kafka 的自动位移提交功能往往会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取。

Kafka 中 enable.auto.commit 参数用来配置自动位移提交功能，默认值为 true，即开启自动位移提交的功能，虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取，所以需要将 enable.auto.commit 参数设置为 false 来执行手动位移提交。

在执行手动位移提交的时候也要遵循一个原则：如果消息没有被成功消费，那么就不能提交所对应的消费位移。

### 回溯消费

对于消费端，Kafka 还提供了一个可以兜底的功能，即回溯消费，通过这个功能可以让我们能够有机会对漏掉的消息相应地进行回补，进而可以进一步提高可靠性。

